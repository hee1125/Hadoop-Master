2017-11-06 23:24:37,328 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = hadoop-master/192.168.252.131
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.2.1
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.2 -r 1503152; compiled by 'mattf' on Mon Jul 22 15:23:09 PDT 2013
STARTUP_MSG:   java = 1.8.0_152
************************************************************/
2017-11-06 23:24:37,460 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-11-06 23:24:37,513 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2017-11-06 23:24:37,514 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-11-06 23:24:37,514 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-11-06 23:24:37,565 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2017-11-06 23:24:37,567 WARN org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Source name ugi already exists!
2017-11-06 23:24:37,571 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2017-11-06 23:24:37,571 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source NameNode registered.
2017-11-06 23:24:37,585 INFO org.apache.hadoop.hdfs.util.GSet: Computing capacity for map BlocksMap
2017-11-06 23:24:37,585 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2017-11-06 23:24:37,585 INFO org.apache.hadoop.hdfs.util.GSet: 2.0% max memory = 932184064
2017-11-06 23:24:37,585 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2017-11-06 23:24:37,585 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2017-11-06 23:24:37,601 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=hadoop
2017-11-06 23:24:37,601 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2017-11-06 23:24:37,601 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2017-11-06 23:24:37,607 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2017-11-06 23:24:37,607 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2017-11-06 23:24:37,808 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStateMBean and NameNodeMXBean
2017-11-06 23:24:37,832 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: dfs.namenode.edits.toleration.length = 0
2017-11-06 23:24:37,832 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2017-11-06 23:24:37,843 INFO org.apache.hadoop.hdfs.server.common.Storage: Start loading image file /var/lib/hadoop/dfs/name/1/current/fsimage
2017-11-06 23:24:37,843 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2017-11-06 23:24:37,845 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2017-11-06 23:24:37,845 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file /var/lib/hadoop/dfs/name/1/current/fsimage of size 112 bytes loaded in 0 seconds.
2017-11-06 23:24:37,845 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Start loading edits file /var/lib/hadoop/dfs/name/1/current/edits
2017-11-06 23:24:37,846 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: EOF of /var/lib/hadoop/dfs/name/1/current/edits, reached end of edit log Number of transactions found: 0.  Bytes read: 4
2017-11-06 23:24:37,846 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Start checking end of edit log (/var/lib/hadoop/dfs/name/1/current/edits) ...
2017-11-06 23:24:37,846 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Checked the bytes after the end of edit log (/var/lib/hadoop/dfs/name/1/current/edits):
2017-11-06 23:24:37,846 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Padding position  = -1 (-1 means padding not found)
2017-11-06 23:24:37,846 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Edit log length   = 4
2017-11-06 23:24:37,846 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Read length       = 4
2017-11-06 23:24:37,846 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Corruption length = 0
2017-11-06 23:24:37,846 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Toleration length = 0 (= dfs.namenode.edits.toleration.length)
2017-11-06 23:24:37,849 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Summary: |---------- Read=4 ----------|-- Corrupt=0 --|-- Pad=0 --|
2017-11-06 23:24:37,849 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edits file /var/lib/hadoop/dfs/name/1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2017-11-06 23:24:37,850 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Start loading edits file /var/lib/hadoop/dfs/name/1/current/edits.new
2017-11-06 23:24:37,850 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Invalid opcode, reached end of edit log Number of transactions found: 0.  Bytes read: 5
2017-11-06 23:24:37,850 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Start checking end of edit log (/var/lib/hadoop/dfs/name/1/current/edits.new) ...
2017-11-06 23:24:37,870 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Checked the bytes after the end of edit log (/var/lib/hadoop/dfs/name/1/current/edits.new):
2017-11-06 23:24:37,870 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Padding position  = 5 (-1 means padding not found)
2017-11-06 23:24:37,870 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Edit log length   = 1048576
2017-11-06 23:24:37,870 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Read length       = 5
2017-11-06 23:24:37,870 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Corruption length = 0
2017-11-06 23:24:37,870 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Toleration length = 0 (= dfs.namenode.edits.toleration.length)
2017-11-06 23:24:37,871 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Summary: |---------- Read=5 ----------|-- Corrupt=0 --|-- Pad=1048571 --|
2017-11-06 23:24:37,871 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edits file /var/lib/hadoop/dfs/name/1/current/edits.new of size 1048576 edits # 0 loaded in 0 seconds.
2017-11-06 23:24:37,872 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file /var/lib/hadoop/dfs/name/1/current/fsimage of size 112 bytes saved in 0 seconds.
2017-11-06 23:24:37,941 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: closing edit log: position=4, editlog=/var/lib/hadoop/dfs/name/1/current/edits
2017-11-06 23:24:37,941 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: close success: truncate to 4, editlog=/var/lib/hadoop/dfs/name/1/current/edits
2017-11-06 23:24:37,947 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file /var/lib/hadoop/dfs/name/2/current/fsimage of size 112 bytes saved in 0 seconds.
2017-11-06 23:24:37,952 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: closing edit log: position=4, editlog=/var/lib/hadoop/dfs/name/2/current/edits
2017-11-06 23:24:37,952 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: close success: truncate to 4, editlog=/var/lib/hadoop/dfs/name/2/current/edits
2017-11-06 23:24:37,959 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-11-06 23:24:37,959 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 369 msecs
2017-11-06 23:24:37,960 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.safemode.threshold.pct          = 0.9990000128746033
2017-11-06 23:24:37,960 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-11-06 23:24:37,960 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.safemode.extension              = 30000
2017-11-06 23:24:37,960 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks excluded by safe block count: 0 total blocks: 0 and thus the safe blocks: 0
2017-11-06 23:24:37,968 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 0
2017-11-06 23:24:37,968 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2017-11-06 23:24:37,968 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 0
2017-11-06 23:24:37,968 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2017-11-06 23:24:37,968 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode termination scan for invalid, over- and under-replicated blocks completed in 8 msec
2017-11-06 23:24:37,968 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2017-11-06 23:24:37,968 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2017-11-06 23:24:37,968 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2017-11-06 23:24:37,971 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2017-11-06 23:24:37,972 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 1 msec
2017-11-06 23:24:37,972 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 1 msec processing time, 1 msec clock time, 1 cycles
2017-11-06 23:24:37,972 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 0 msec
2017-11-06 23:24:37,972 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 0 msec processing time, 0 msec clock time, 1 cycles
2017-11-06 23:24:37,973 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source FSNamesystemMetrics registered.
2017-11-06 23:24:37,985 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2017-11-06 23:24:37,986 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcDetailedActivityForPort9000 registered.
2017-11-06 23:24:37,986 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcActivityForPort9000 registered.
2017-11-06 23:24:37,987 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up at: hadoop-master/192.168.252.131:9000
2017-11-06 23:24:38,070 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-11-06 23:24:38,109 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2017-11-06 23:24:38,116 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = true
2017-11-06 23:24:38,117 INFO org.apache.hadoop.http.HttpServer: Added filter 'SPNEGO' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-11-06 23:24:38,117 INFO org.apache.hadoop.http.HttpServer: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-11-06 23:24:38,129 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2017-11-06 23:24:38,132 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2017-11-06 23:24:38,132 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2017-11-06 23:24:38,132 INFO org.mortbay.log: jetty-6.1.26
2017-11-06 23:24:38,328 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: 'signature.secret' configuration not set, using a random value as secret
2017-11-06 23:24:38,356 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2017-11-06 23:24:38,356 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2017-11-06 23:24:38,357 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-11-06 23:24:38,358 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2017-11-06 23:24:38,358 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 9000: starting
2017-11-06 23:24:38,359 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 9000: starting
2017-11-06 23:24:38,359 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9000: starting
2017-11-06 23:24:38,360 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 9000: starting
2017-11-06 23:24:38,364 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 9000: starting
2017-11-06 23:24:38,364 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 9000: starting
2017-11-06 23:24:38,364 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 9000: starting
2017-11-06 23:24:38,364 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 9000: starting
2017-11-06 23:24:38,365 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 9000: starting
2017-11-06 23:24:38,365 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 9000: starting
