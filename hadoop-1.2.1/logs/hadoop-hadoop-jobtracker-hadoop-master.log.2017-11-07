2017-11-07 04:46:11,148 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = hadoop-master/192.168.252.131
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.2.1
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.2 -r 1503152; compiled by 'mattf' on Mon Jul 22 15:23:09 PDT 2013
STARTUP_MSG:   java = 1.8.0_152
************************************************************/
2017-11-07 04:46:11,240 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-11-07 04:46:11,245 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2017-11-07 04:46:11,246 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-11-07 04:46:11,246 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: JobTracker metrics system started
2017-11-07 04:46:11,267 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source QueueMetrics,q=default registered.
2017-11-07 04:46:11,412 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2017-11-07 04:46:11,412 WARN org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Source name ugi already exists!
2017-11-07 04:46:11,412 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2017-11-07 04:46:11,413 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2017-11-07 04:46:11,413 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2017-11-07 04:46:11,413 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2017-11-07 04:46:11,414 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2017-11-07 04:46:11,420 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hadoop
2017-11-07 04:46:11,430 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2017-11-07 04:46:11,431 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcDetailedActivityForPort9001 registered.
2017-11-07 04:46:11,431 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcActivityForPort9001 registered.
2017-11-07 04:46:11,486 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-11-07 04:46:11,516 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2017-11-07 04:46:11,518 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2017-11-07 04:46:11,518 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2017-11-07 04:46:11,518 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2017-11-07 04:46:11,518 INFO org.mortbay.log: jetty-6.1.26
2017-11-07 04:46:11,682 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2017-11-07 04:46:11,704 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2017-11-07 04:46:11,704 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source JobTrackerMetrics registered.
2017-11-07 04:46:11,711 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 9001
2017-11-07 04:46:11,711 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2017-11-07 04:46:11,715 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-11-07 04:46:11,715 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9001: starting
2017-11-07 04:46:11,716 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 9001: starting
2017-11-07 04:46:11,716 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 9001: starting
2017-11-07 04:46:11,716 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9001: starting
2017-11-07 04:46:11,716 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 9001: starting
2017-11-07 04:46:11,716 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 9001: starting
2017-11-07 04:46:11,716 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 9001: starting
2017-11-07 04:46:11,716 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 9001: starting
2017-11-07 04:46:11,716 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 9001: starting
2017-11-07 04:46:11,716 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 9001: starting
2017-11-07 04:46:11,716 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 9001: starting
2017-11-07 04:46:11,716 INFO org.apache.hadoop.mapred.JobTracker: Setting safe mode to true. Requested by : hadoop
2017-11-07 04:46:12,752 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:13,753 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:14,754 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:15,756 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:16,757 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:17,758 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:18,761 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:19,763 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:20,765 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:21,767 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:21,769 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:hadoop cause:java.net.ConnectException: Call to hadoop-master/192.168.252.131:9000 failed on connection exception: java.net.ConnectException: Connection refused
2017-11-07 04:46:21,770 INFO org.apache.hadoop.mapred.JobTracker: Problem connecting to HDFS Namenode... re-trying
java.net.ConnectException: Call to hadoop-master/192.168.252.131:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1142)
	at org.apache.hadoop.ipc.Client.call(Client.java:1118)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy6.getProtocolVersion(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:85)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:62)
	at com.sun.proxy.$Proxy6.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.checkVersion(RPC.java:422)
	at org.apache.hadoop.hdfs.DFSClient.createNamenode(DFSClient.java:183)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:281)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:245)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:100)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1446)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:67)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1464)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:263)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:124)
	at org.apache.hadoop.mapred.JobTracker$2.run(JobTracker.java:1708)
	at org.apache.hadoop.mapred.JobTracker$2.run(JobTracker.java:1706)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.mapred.JobTracker.initializeFilesystem(JobTracker.java:1706)
	at org.apache.hadoop.mapred.JobTracker.offerService(JobTracker.java:2143)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4711)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:511)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:481)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:457)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:583)
	at org.apache.hadoop.ipc.Client$Connection.access$2200(Client.java:205)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1249)
	at org.apache.hadoop.ipc.Client.call(Client.java:1093)
	... 27 more
2017-11-07 04:46:23,773 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:24,775 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:25,777 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:26,780 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:27,782 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:28,784 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:29,786 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:30,788 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:31,791 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:32,793 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:32,795 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:hadoop cause:java.net.ConnectException: Call to hadoop-master/192.168.252.131:9000 failed on connection exception: java.net.ConnectException: Connection refused
2017-11-07 04:46:32,795 INFO org.apache.hadoop.mapred.JobTracker: Problem connecting to HDFS Namenode... re-trying
java.net.ConnectException: Call to hadoop-master/192.168.252.131:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1142)
	at org.apache.hadoop.ipc.Client.call(Client.java:1118)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy6.getProtocolVersion(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:85)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:62)
	at com.sun.proxy.$Proxy6.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.checkVersion(RPC.java:422)
	at org.apache.hadoop.hdfs.DFSClient.createNamenode(DFSClient.java:183)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:281)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:245)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:100)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1446)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:67)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1464)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:263)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:124)
	at org.apache.hadoop.mapred.JobTracker$2.run(JobTracker.java:1708)
	at org.apache.hadoop.mapred.JobTracker$2.run(JobTracker.java:1706)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.mapred.JobTracker.initializeFilesystem(JobTracker.java:1706)
	at org.apache.hadoop.mapred.JobTracker.offerService(JobTracker.java:2143)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4711)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:511)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:481)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:457)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:583)
	at org.apache.hadoop.ipc.Client$Connection.access$2200(Client.java:205)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1249)
	at org.apache.hadoop.ipc.Client.call(Client.java:1093)
	... 27 more
2017-11-07 04:46:34,800 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:35,803 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:36,804 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:37,807 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:38,809 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:39,810 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:40,812 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:41,815 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:42,817 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:43,819 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:43,821 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:hadoop cause:java.net.ConnectException: Call to hadoop-master/192.168.252.131:9000 failed on connection exception: java.net.ConnectException: Connection refused
2017-11-07 04:46:43,821 INFO org.apache.hadoop.mapred.JobTracker: Problem connecting to HDFS Namenode... re-trying
java.net.ConnectException: Call to hadoop-master/192.168.252.131:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1142)
	at org.apache.hadoop.ipc.Client.call(Client.java:1118)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy6.getProtocolVersion(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:85)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:62)
	at com.sun.proxy.$Proxy6.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.checkVersion(RPC.java:422)
	at org.apache.hadoop.hdfs.DFSClient.createNamenode(DFSClient.java:183)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:281)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:245)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:100)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1446)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:67)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1464)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:263)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:124)
	at org.apache.hadoop.mapred.JobTracker$2.run(JobTracker.java:1708)
	at org.apache.hadoop.mapred.JobTracker$2.run(JobTracker.java:1706)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.mapred.JobTracker.initializeFilesystem(JobTracker.java:1706)
	at org.apache.hadoop.mapred.JobTracker.offerService(JobTracker.java:2143)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4711)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:511)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:481)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:457)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:583)
	at org.apache.hadoop.ipc.Client$Connection.access$2200(Client.java:205)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1249)
	at org.apache.hadoop.ipc.Client.call(Client.java:1093)
	... 27 more
2017-11-07 04:46:45,824 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:46,826 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:47,829 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:48,831 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:49,834 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:50,835 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:51,837 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:52,839 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop-master/192.168.252.131:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2017-11-07 04:46:53,523 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at hadoop-master/192.168.252.131
************************************************************/
2017-11-07 05:00:04,761 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = hadoop-master/192.168.252.131
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.2.1
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.2 -r 1503152; compiled by 'mattf' on Mon Jul 22 15:23:09 PDT 2013
STARTUP_MSG:   java = 1.8.0_152
************************************************************/
2017-11-07 05:00:04,816 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-11-07 05:00:04,821 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2017-11-07 05:00:04,822 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-11-07 05:00:04,822 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: JobTracker metrics system started
2017-11-07 05:00:04,844 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source QueueMetrics,q=default registered.
2017-11-07 05:00:04,992 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2017-11-07 05:00:04,992 WARN org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Source name ugi already exists!
2017-11-07 05:00:04,993 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2017-11-07 05:00:04,994 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2017-11-07 05:00:04,994 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2017-11-07 05:00:04,994 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2017-11-07 05:00:04,994 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2017-11-07 05:00:05,002 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hadoop
2017-11-07 05:00:05,011 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2017-11-07 05:00:05,012 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcDetailedActivityForPort9001 registered.
2017-11-07 05:00:05,012 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcActivityForPort9001 registered.
2017-11-07 05:00:05,071 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-11-07 05:00:05,095 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2017-11-07 05:00:05,097 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50030
2017-11-07 05:00:05,097 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50030 webServer.getConnectors()[0].getLocalPort() returned 50030
2017-11-07 05:00:05,097 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50030
2017-11-07 05:00:05,097 INFO org.mortbay.log: jetty-6.1.26
2017-11-07 05:00:05,227 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50030
2017-11-07 05:00:05,237 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2017-11-07 05:00:05,238 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source JobTrackerMetrics registered.
2017-11-07 05:00:05,245 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 9001
2017-11-07 05:00:05,245 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2017-11-07 05:00:05,249 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-11-07 05:00:05,249 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9001: starting
2017-11-07 05:00:05,250 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 9001: starting
2017-11-07 05:00:05,250 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 9001: starting
2017-11-07 05:00:05,250 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9001: starting
2017-11-07 05:00:05,250 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 9001: starting
2017-11-07 05:00:05,250 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 9001: starting
2017-11-07 05:00:05,250 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 9001: starting
2017-11-07 05:00:05,250 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 9001: starting
2017-11-07 05:00:05,251 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 9001: starting
2017-11-07 05:00:05,251 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 9001: starting
2017-11-07 05:00:05,251 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 9001: starting
2017-11-07 05:00:05,251 INFO org.apache.hadoop.mapred.JobTracker: Setting safe mode to true. Requested by : hadoop
2017-11-07 05:00:05,303 INFO org.apache.hadoop.mapred.JobTracker: Setting safe mode to false. Requested by : hadoop
2017-11-07 05:00:05,308 INFO org.apache.hadoop.util.NativeCodeLoader: Loaded the native-hadoop library
2017-11-07 05:00:05,322 INFO org.apache.hadoop.mapred.JobTracker: Cleaning up the system directory
2017-11-07 05:00:05,340 INFO org.apache.hadoop.mapred.JobHistory: Creating DONE folder at file:/opt/hadoop-1.2.1/logs/history/done
2017-11-07 05:00:05,343 INFO org.apache.hadoop.mapred.JobHistory: Job History MaxAge is 2592000000 ms (30.00 days), Cleanup Frequency is 86400000 ms (1.00 days)
2017-11-07 05:00:05,343 INFO org.apache.hadoop.mapred.JobTracker: History server being initialized in embedded mode
2017-11-07 05:00:05,348 INFO org.apache.hadoop.mapred.JobHistoryServer: Started job history server at: localhost:50030
2017-11-07 05:00:05,348 INFO org.apache.hadoop.mapred.JobTracker: Job History Server web address: localhost:50030
2017-11-07 05:00:05,348 INFO org.apache.hadoop.mapred.CompletedJobStatusStore: Completed job store is inactive
2017-11-07 05:00:05,464 INFO org.apache.hadoop.mapred.JobTracker: Starting the recovery process for 0 jobs ...
2017-11-07 05:00:05,464 INFO org.apache.hadoop.mapred.JobTracker: Recovery done! Recoverd 0 of 0 jobs.
2017-11-07 05:00:05,464 INFO org.apache.hadoop.mapred.JobTracker: Recovery Duration (ms):0
2017-11-07 05:00:05,464 INFO org.apache.hadoop.mapred.JobTracker: Refreshing hosts information
2017-11-07 05:00:05,471 INFO org.apache.hadoop.util.HostsFileReader: Setting the includes file to 
2017-11-07 05:00:05,471 INFO org.apache.hadoop.util.HostsFileReader: Setting the excludes file to 
2017-11-07 05:00:05,471 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2017-11-07 05:00:05,471 INFO org.apache.hadoop.mapred.JobTracker: Decommissioning 0 nodes
2017-11-07 05:00:05,473 INFO org.apache.hadoop.mapred.JobTracker: Starting RUNNING
2017-11-07 05:07:18,491 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/hadoop-worker01
2017-11-07 05:07:18,492 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_hadoop-worker01:localhost/127.0.0.1:45106 to host hadoop-worker01
2017-11-07 05:08:51,001 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/hadoop-worker02
2017-11-07 05:08:51,001 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_hadoop-worker02:localhost/127.0.0.1:37809 to host hadoop-worker02
2017-11-07 05:12:01,877 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/hadoop-worker03
2017-11-07 05:12:01,878 INFO org.apache.hadoop.mapred.JobTracker: Adding tracker tracker_hadoop-worker03:localhost/127.0.0.1:34517 to host hadoop-worker03
2017-11-07 05:44:11,102 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at hadoop-master/192.168.252.131
************************************************************/
